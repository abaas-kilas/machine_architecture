                           _________________

                            HW 13 QUESTIONS
                           _________________


- Name: (FILL THIS in)
- X.500: (THE kauf0095 IN kauf0095@umn.edu)

Write your answers to the questions below directly in this text file to
prepare for the associated quiz.


PROBLEM 1: Cache and Loop Iterations
====================================

  Below are tables showing values in Main Memory and the state of a
  small Cache.  Beneath this is a short code fragment that sums elements
  from main memory. The code has a user parameter `stride'. For strides
  of 1,2,3,4, work through the code changing cache and counting how many
  cache hits/misses occur with the given stride. Show the final state of
  cache in each case.


Main Memory
~~~~~~~~~~~

  ,----
  | | Addr | Addr Bits      | Value |
  | |------+----------------+-------|
  | |   20 | 00  10  0000   |     9 |
  | |   24 | 00  10  0100   |    10 |
  | |   28 | 00  10  1000   |    11 |
  | |   2C | 00  10  1100   |    12 |
  | |   30 | 00  11  0000   |    13 |
  | |   34 | 00  11  0100   |    14 |
  | |   38 | 00  11  1000   |    15 |
  | |   3C | 00  11  1100   |    16 |
  | |   40 | 01  00  0000   |    17 |
  | |   44 | 01  00  0100   |    18 |
  | |   48 | 01  00  1000   |    19 |
  | |   4C | 01  00  1100   |    20 |
  | |   50 | 01  01  0000   |    21 |
  | |   54 | 01  01  0100   |    22 |
  | |   58 | 01  01  1000   |    23 |
  | |   5C | 01  01  1100   |    24 |
  | |   60 | 01  10  0000   |    25 |
  | |   64 | 01  10  0100   |    26 |
  | |   68 | 01  10  1000   |    27 |
  | |   6C | 01  10  1100   |    28 |
  | |------+----------------+-------|
  | |      | Tag Set Offset |       |
  `----


Cache
~~~~~

  - Direct-mapped: 1 line per set
  - 16-byte lines = 4-bit offset
  - 4 Sets = 2-bit index
  - 8-bit Address = 2-bit tag
  - Total Cache Size = 64 bytes 4 sets * 16 bytes
  - Mostly cold with some data from an earlier part of the code

  ,----
  | |     |   |     | Blocks/Line           |
  | | Set | V | Tag | 0-3  4-7  8-11  12-15 |
  | |-----+---+-----+-----------------------|
  | |  00 | 1 | 00  | 1    2    3     4     |
  | |  01 | 0 | -   | -                     |
  | |  10 | 0 | -   | -                     |
  | |  11 | 0 | -   | -                     |
  | |-----+---+-----+-----------------------|
  | | Set | V | Tag | 0-3  4-7  8-11  12-15 |
  `----


Code
~~~~

  ,----
  | int *data = (int *) 0x20;           // address of start of the array
  | int stride; scanf("%d", &stride);   // user enters 1, 2, 3, or other values
  | int sum = 0;
  | for(int i=0; i<20; i += stride){
  |   sum += data[i];
  | }
  `----


Stats for Strides:
~~~~~~~~~~~~~~~~~~

  Show sum, number of hits/misses, and final cache state for strides of
  1,2,3,4.
  - Stride 1: sum, misses/hits, final cache state
  - Stride 2: sum, misses/hits, final cache state
  - Stride 3: sum, misses/hits, final cache state
  - Stride 4: sum, misses/hits, final cache state


Solution                                                      :solution:
--------

  All strides have the following final cache state
  ,----
  | |     |   |     | Blocks/Line |                                                                            |
  | | Set | V | Tag | 0  4  8  12 | Notes                                                                      |
  | |-----+---+-----+-------------+----------------------------------------------------------------------------|
  | |  00 | 1 |  01 | 17 18 19 20 | Original contents '1 2 3 4' evicted midway through the loop                |
  | |  01 | 1 |  01 | 21 22 23 24 |                                                                            |
  | |  10 | 1 |  01 | 25 26 27 28 | First loop iteration loads '9 10 11 12' which is evicted in last iteration |
  | |  11 | 1 |  00 | 13 14 15 16 |                                                                            |
  | |-----+---+-----+-------------+----------------------------------------------------------------------------|
  | | Set | V | Tag | 0  4  8  12 |                                                                            |
  `----

  Miss/Hit Diagram for Strides
  ,----
  | | Addr | Addr Bits      | Value |  i | Stride1 | Stride2 |  i | Stride3 | Stride4 |
  | |------+----------------+-------+----+---------+---------+----+---------+---------|
  | |   20 | 00  10  0000   |     9 |  0 | Miss    | Miss    |  0 | Miss    | Miss    |
  | |   24 | 00  10  0100   |    10 |  1 | Hit     |         |  1 |         |         |
  | |   28 | 00  10  1000   |    11 |  2 | Hit     | Hit     |  2 |         |         |
  | |   2C | 00  10  1100   |    12 |  3 | Hit     |         |  3 | Hit     |         |
  | |   30 | 00  11  0000   |    13 |  4 | Miss    | Miss    |  4 |         | Miss    |
  | |   34 | 00  11  0100   |    14 |  5 | Hit     |         |  5 |         |         |
  | |   38 | 00  11  1000   |    15 |  6 | Hit     | Hit     |  6 | Miss    |         |
  | |   3C | 00  11  1100   |    16 |  7 | Hit     |         |  7 |         |         |
  | |   40 | 01  00  0000   |    17 |  8 | Miss    | Miss    |  8 |         | Miss    |
  | |   44 | 01  00  0100   |    18 |  9 | Hit     |         |  9 | Miss    |         |
  | |   48 | 01  00  1000   |    19 | 10 | Hit     | Hit     | 10 |         |         |
  | |   4C | 01  00  1100   |    20 | 11 | Hit     |         | 11 |         |         |
  | |   50 | 01  01  0000   |    21 | 12 | Miss    | Miss    | 12 | Miss    | Miss    |
  | |   54 | 01  01  0100   |    22 | 13 | Hit     |         | 13 |         |         |
  | |   58 | 01  01  1000   |    23 | 14 | Hit     | Hit     | 14 |         |         |
  | |   5C | 01  01  1100   |    24 | 15 | Hit     |         | 15 | Hit     |         |
  | |   60 | 01  10  0000   |    25 | 16 | Miss    | Miss    | 16 |         | Miss    |
  | |   64 | 01  10  0100   |    26 | 17 | Hit     |         | 17 |         |         |
  | |   68 | 01  10  1000   |    27 | 18 | Hit     | Hit     | 18 | Miss    |         |
  | |   6C | 01  10  1100   |    28 | 19 | Hit     |         | 19 |         |         |
  | |------+----------------+-------+----+---------+---------+----+---------+---------|
  | |      | Tag Set Offset |       |    |         |         |    |         |         |
  `----

  Totals
   Stride  Sum  Misses  Hits 
  ---------------------------
        1  370       5    15 
        2  180       5     5 
        3  126       5     2 
        4   85       5     0 

  For smaller strides, the favorable ratio of Hits to Misses explains
  the better throughput observed in practice.


PROBLEM 2: Timing Benchmarks
============================

  The code in `reversal_benchmark.c' implements two functions which
  reverse the elements of an array. They take markedly different
  approaches.
  ,----
  | void reverse_arr1(int *arr, long size){
  |   int *tmp = malloc(sizeof(int)*size);
  |   for(long i=0; i<size; i++){
  |     tmp[i] = arr[size-i-1];
  |   }
  |   for(long i=0; i<size; i++){
  |     arr[i] = tmp[i];
  |   }
  |   free(tmp);
  | }
  | 
  | void reverse_arr2(int *arr, long size){
  |   for(long i=0; i<size/2; i++){
  |     int tmp = arr[i];
  |     arr[i] = arr[size-i-1];
  |     arr[size-i-1] = tmp;
  |   }
  | }
  `----


(A) Predictions
~~~~~~~~~~~~~~~

  Predict which of these two functions will run faster based on their
  code characteristics. Justify your answer by contrasting the features
  of the two reversal functions.


Solution                                                      :solution:
--------

  `reverse_arr1()' seems less likely to perform well because
  - it makes two passes through the array meaning it utilizes cache less
    effectively than `reverse_arr2()'
  - the second loop pass means that there is additional loop overhead to
    increment counters and perform boundary checks
  - memory is allocated and then free'd which takes time that is not
    spent in reverse_arr2


(B) Timing
~~~~~~~~~~

  Modify the provided `reversal_benchmark.c' file to perform timing
  calculations on the two functions as they are called on different
  sizes of arrays.  Print runtimes in a tabular format.

  Make sure to compile/run with a convention like the following:
  ,----
  | > gcc -Og reversal_benchmark.c    # compile with minimal optimizations
  | 
  | > ./a.out                         # show usage
  | usage: ./a.out <min_pow2> <max_pow2> <repeats>
  | 
  | > ./a.out 10 20 100               # run benchmark, size 2^10 to 2^20, 100 repeats per
  |       SIZE       rev1       rev2
  |       1024       ???        ???
  |       2048       ???        ???
  |       4096       ???        ???
  |       8192       ???        ???
  |      16384       ???        ???
  |      32768       ???        ???
  |      65536       ???        ???
  |     131072       ???        ???
  |     262144       ???        ???
  |     524288       ???        ???
  |    1048576       ???        ???
  `----



  Paste the C code you wrote below to show you how you timed the
  function runs.


Solution                                                      :solution:
--------

  ,----
  | // In loop over sizes 
  |     clock_t begin, end;
  |     
  |     begin = clock();
  |     for(int i=0; i<repeats; i++){ // repeatedly run function
  |       reverse_arr1(arr1,size);
  |     }
  |     end = clock();
  |     double cpu_time1 = ((double) (end - begin)) / CLOCKS_PER_SEC;
  |     printf("%10.4e ",cpu_time1);
  |       
  |     begin = clock();
  |     for(int i=0; i<repeats; i++){ // repeatedly run function
  |       reverse_arr2(arr2,size);
  |     }
  |     end = clock();
  |     double cpu_time2 = ((double) (end - begin)) / CLOCKS_PER_SEC;
  |     printf("%10.4e ",cpu_time2);
  | 
  `----


(C) Analysis
~~~~~~~~~~~~

  Paste the table of numbers your code produced for timing the two
  reversal functions. Describe if the one you predicted would be faster
  actually was measured to be faster.


Solution                                                      :solution:
--------

  ,----
  | val> ./a.out 10 20 100  # run benchmark
  |       SIZE       rev1       rev2   rev_OPTM 
  |       1024 4.1300e-04 2.3100e-04 1.4300e-04 
  |       2048 8.0300e-04 4.5600e-04 2.7900e-04 
  |       4096 1.2870e-03 2.1300e-04 1.3000e-04 
  |       8192 7.7700e-04 4.2500e-04 2.5900e-04 
  |      16384 1.5420e-03 8.4600e-04 5.1700e-04 
  |      32768 4.3180e-03 2.2670e-03 1.3730e-03 
  |      65536 8.2900e-03 3.8690e-03 2.7980e-03 
  |     131072 1.5041e-02 7.9850e-03 4.4940e-03 
  |     262144 3.1649e-02 1.3665e-02 9.0430e-03 
  |     524288 5.8907e-02 2.7332e-02 1.8127e-02 
  |    1048576 1.2882e-01 5.5805e-02 3.7581e-02 
  `----

  `array_rev2()' is definitely faster at all sizes measured taking only
  1/2 to 1/3 of the time as `array_rev1()' at the most sizes.

  The last column shows the results of the optional optimized version of
  `array_rev2()'


(D) OPTIONAL: Optimized Reversal
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  After determining the faster reversal function, modify it further in
  an attempt to further improve its performance.


Solution                                                      :solution:
--------

  Unrolling the loop in `reverse_arr2()' is sufficient to improve the
  performance though this requires a touch of care to get the indices
  correct.  See the table above for empirical results on an Intel
  laptop.
  ,----
  | 
  | // based on reverse_arr2() + unrolling
  | void reverse_arr_OPTM(int *arr, long size){
  |   long i;
  | 
  |   for(i=0; i<size/2-4; i+=4){   // unrolled loop
  |     int tmp0 = arr[i+0];
  |     arr[i+0] = arr[size-i-1-0];
  |     arr[size-i-1-0] = tmp0;
  | 
  |     int tmp1 = arr[i+1];
  |     arr[i+1] = arr[size-i-1-1];
  |     arr[size-i-1-1] = tmp1;
  | 
  |     int tmp2 = arr[i+2];
  |     arr[i+2] = arr[size-i-1-2];
  |     arr[size-i-1-2] = tmp2;
  | 
  |     int tmp3 = arr[i+3];
  |     arr[i+3] = arr[size-i-1-3];
  |     arr[size-i-1-3] = tmp3;
  |   }
  | 
  |   for(; i<size/2; i+=1){     // cleanup
  |     int tmp0 = arr[i+0];
  |     arr[i+0] = arr[size-i-1-0];
  |     arr[size-i-1-0] = tmp0;
  |   }
  | }
  `----


PROBLEM 3: ax then xpy VS axpy
==============================

  Examine the timing code in `axpy.c'. Consider the 3 functions `ax()',
  `xpy()', and `axpy()'.  Note that these are timed in `main()' as
  follows.
  ,----
  | // start timing 1
  |     ax(a,x1,size);
  |     xpy(x1,y,size);
  | // stop timing
  | 
  | // start timing 2
  |     axpy(a,x2,y,size);
  | // stop timing
  `----
  This is because the first two functions together do what `axpy()'
  does.

  Note also that `axpy()' has two "fairness" loops which do affect the
  results but compensate for the fact that the previous two functions
  combined have two loops.

  Time these functions using the provided code. Explain the results you
  observe and if one appears to be faster than the other, describe what
  features of the processor and memory architecture might be affecting
  the timings.


Solution                                                      :solution:
--------

  ,----
  | apollo> gcc -Og axpy.c
  | apollo> ./a.out 22 28
  |       SIZE     ax xpy       axpy 
  |    4194304 5.6086e-02 3.2199e-02 
  |    8388608 1.0948e-01 6.4968e-02 
  |   16777216 2.6668e-01 1.5806e-01 
  |   33554432 5.4545e-01 3.1933e-01 
  |   67108864 5.0473e-01 3.2807e-01 
  |  134217728 9.6615e-01 6.0897e-01 
  |  268435456 2.9496e+00 1.3581e+00 
  `----

  axpy() is faster at all levels. This is could be for a couple reasons.
  - It makes only one pass through both arrays meaning it is more
    efficiently using cache
  - The fact that multiple adds/multiplies are being used may allow for
    pipelining and/or superscalar execution where adds/multiplies are
    simultaneously executed.  This cannot happen as readily in the first
    two as the adds and multiplies are spread across two separate
    functions.


PROBLEM 4 (OPTIONAL): Profiler
==============================

  This problem demonstrates the utility of a performance *profiler* to
  help locate "hot spots" in code which take most of the run time
  associated with it.

  Change into the directory `warsim' that is part of the HW code
  distribution.  The code contained within it implements a simple
  simulation of the card game War.  The details of the game are not
  important except that the program simulates playing of the game then
  reports statistics on it.

  First compile the program by using the provided Makefile.
  ,----
  | > make
  | gcc -Og -g -pg -no-pie -c libwar.c
  | gcc -Og -g -pg -no-pie -c libcardlist.c
  | gcc -Og -g -pg -no-pie -o warsim warsim.c libwar.o libcardlist.o
  `----
  Notice that the option `-pg' is passed in which will enable
  /profiling/ of the code. The `-no-pie' option is present in case a
  buggy version of `gcc' is present and has no significant effect.

  Run the resulting `warsim' program as follows.

  ,----
  | # show usage
  | > ./warsim
  | usage: ./warsim cardfile ngames [logfile]
  | 
  | # simulate 10 games
  | > ./warsim full.deck 10
  | ----------------------
  | Final stats
  |   0.60 P1 Win Ratio
  | 408.50 Avg battles per game
  |  30.30 Avg wars per game
  | 
  | # simulate 100 games
  | > ./warsim full.deck 100
  | ----------------------
  | Final stats
  |   0.54 P1 Win Ratio
  | 301.56 Avg battles per game
  |  22.94 Avg wars per game
  | 
  | # simulate 2000 games
  | > ./warsim full.deck 2000
  | ----------------------
  | Final stats
  |   0.54 P1 Win Ratio
  | 298.48 Avg battles per game
  |  22.79 Avg wars per game
  `----

  This last run might take a few seconds as 2000 games are simulated.

  After the runs are finished, the file `gmon.out' appears. This is an
  output file that is generated on running programs with profiling
  enabled.
  ,----
  | > ls gmon.out
  | gmon.out
  | > file gmon.out
  | gmon.out: GNU prof performance data - version 1
  `----

  The contents of the file are binary and must be interpreted by the
  program `gprof'.  Use the `-b' option to show "brief" output and pass
  in the name of the program that was run.
  ,----
  | > gprof -b warsim
  | Flat profile:
  | 
  | Each sample counts as 0.01 seconds.
  |   %   cumulative   self              self     total           
  |  time   seconds   seconds    calls  ms/call  ms/call  name    
  |  50.11      0.06     0.06  2387860     0.00     0.00  print_list
  |  25.06      0.09     0.03 32507650     0.00     0.00  card2str
  |   8.35      0.10     0.01   596965     0.00     0.00  end_battle
  |   8.35      0.11     0.01     4000     0.00     0.00  new_stack
  |   8.35      0.12     0.01       52     0.19     0.19  str2card
  |   0.00      0.12     0.00  8073378     0.00     0.00  stack_empty
  |   0.00      0.12     0.00  6656812     0.00     0.00  queue_empty
  |   0.00      0.12     0.00  3944508     0.00     0.00  stack_top
  |   0.00      0.12     0.00  1675522     0.00     0.00  queue_add
  |   0.00      0.12     0.00  1675522     0.00     0.00  queue_remove
  |   0.00      0.12     0.00  1571470     0.00     0.00  queue_front
  |   0.00      0.12     0.00  1465470     0.00     0.00  stack_pop
  |   0.00      0.12     0.00  1465470     0.00     0.00  stack_push
  |   0.00      0.12     0.00   596965     0.00     0.00  start_battle
  |   0.00      0.12     0.00     6001     0.00     0.00  new_queue
  |   0.00      0.12     0.00     6001     0.00     0.00  queue_free
  |   0.00      0.12     0.00     4000     0.00     0.00  stack_free
  |   0.00      0.12     0.00     2000     0.00     0.00  deal2
  |   0.00      0.12     0.00     2000     0.00     0.06  playwar
  |   0.00      0.12     0.00     2000     0.00     0.00  queue_copy
  |   0.00      0.12     0.00     2000     0.00     0.00  queue_rotate
  |   0.00      0.12     0.00        1     0.00    10.02  read_deck
  | ...
  `----

  The first part of the output shows a breakdown of how much time was
  spent in each function associated the most recent run of the program.

  Analyze this breakdown and make suggestions as to where optimization
  effort might best be spent to increase the speed of warsim.


Solution                                                      :solution:
--------

  Clearly a lot of time is spent in the print_list and card2str
  functions so optimizing these might help.  They occupy 50% and 25% of
  the sampled time so would cut out a lot of computation if improved.
  In truth, these are output functions and avoiding calling them
  altogether would be useful. This would involve re-arranging some code
  to disable output in the likely case that it is not needed for large
  runs.
